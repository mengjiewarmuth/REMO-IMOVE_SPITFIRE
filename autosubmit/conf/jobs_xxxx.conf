# Autosubmit job configuration file for a REMO test workflow
# Possible options are explained below

[REMOTE_SETUP]
FILE = autosubmit/jobs/remote_setup.sh
PLATFORM = LOCAL

[MODEL_SETUP]
FILE = autosubmit/jobs/model_setup.sh
PLATFORM = DKRZ
WALLCLOCK = 30
QUEUE = shared
DEPENDENCIES = REMOTE_SETUP

[MEMBER_SETUP]
FILE = autosubmit/jobs/member_setup.py
RUNNING = member
PLATFORM = DKRZ
WALLCLOCK = 30
QUEUE = shared
TYPE = python
DEPENDENCIES = REMOTE_SETUP

[BOUNDARY_SETUP]
FILE = autosubmit/jobs/ret_forcing.sh
RUNNING = chunk
PLATFORM = DKRZ
WALLCLOCK = 30
QUEUE = shared
DEPENDENCIES = MEMBER_SETUP MODEL_SETUP SIM-1

[SIM]
FILE = autosubmit/jobs/test_remo.sh
DEPENDENCIES = BOUNDARY_SETUP
RUNNING = chunk
PLATFORM = DKRZ
WALLCLOCK = 30
PROCESSORS = 24

[POSTPROCESS]
FILE = autosubmit/jobs/postprocess.sh
RUNNING = chunk
PLATFORM = DKRZ
WALLCLOCK = 30
QUEUE = shared
DEPENDENCIES = SIM

[PUT]
FILE = autosubmit/jobs/putscript.py
RUNNING = chunk
PLATFORM = DKRZ
WALLCLOCK = 30
QUEUE = shared
DEPENDENCIES = POSTPROCESS
TYPE = python
FREQUENCY = 12

## Job name
# [JOBNAME]

## Script to execute. If not specified, job will be omitted from workflow.
## Path relative to the project directory
# FILE =

## Platform to execute the job. If not specified,
## defaults to HPCARCH in expdef file.
## LOCAL is always defined and represents the current machine
# PLATFORM =

## Queue to add the job to. If not specified, uses PLATFORM default.
# QUEUE =

## Defines dependencies from job as a list of parents jobs separated by spaces.
## Dependencies to jobs in previous chunk, member o startdate, use -(DISTANCE)
# DEPENDENCIES = INI SIM-1 CLEAN-2

## Define if jobs runs once, once per stardate, once per member or
## once per chunk. Options: once, date, member, chunk.
## If not specified, defaults to once
# RUNNING = once

## Specifies that job has only to be run after X dates, members or chunk.
## A job will always be created for the last
## If not specified, defaults to 1
# FREQUENCY = 1

## Specifies if a job with FREQUENCY > 1 has only to wait for all the jobs
## in the previous chunks on its period or just for the ones in the chunk
## it is going to execute.
## If not specified, defaults to True
# WAIT = False

## Defines if job is only to be executed in reruns.
## If not specified, defaults to false.
# RERUN_ONLY = False

## Defines jobs needed to be rerun if this job is going to be rerunned
# RERUN_DEPENDENCIES = RERUN INI LOCAL_SETUP REMOTE_SETUP TRANSFER

## Wallclock to be submitted to the HPC queue in format HH:MM.
## If not specified, defaults to empty.
# WALLCLOCK = 00:05

## Processors number to be submitted to the HPC.
## If not specified, defaults to 1.
## FOR REMO: This number should be equal to (NPROCXM * NPROCYM) that are given
## in the project config file.
# PROCESSORS = 1

## Threads number to be submitted to the HPC. If not specified, defaults to 1.
# THREADS = 1

## Tasks number (number of processes per node) to be submitted to the HPC.
## If not specified, defaults to empty.
# TASKS = 16

## Memory requirements for the job in MB. If not specified, defaults to empty.
# MEMORY = 4096

## Scratch free space requirements for the job in percentage (%).
## If not specified, it won't be defined on the template.
# SCRATCH_FREE_SPACE = 10

## Number of retrials if a job fails.
## If not specified, defaults to the value given on experiment's autosubmit.conf
# RETRIALS = 4

## Some jobs can not be checked before running previous jobs.
## Set this option to false if that is the case
# CHECK = False

## Select the interpreter that will run the job.
## Options: bash, python, r Default: bash
# TYPE = bash

## Synchronize a chunk job with its dependency chunks at a 'date'
## or 'member' level
# SYNCHRONIZE = date | member
